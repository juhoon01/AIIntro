train loss:1.655565020705263
train loss:1.5612756907455403
train loss:1.4585565355572834
train loss:1.2870372785356456
train loss:1.1865707290576069
train loss:1.201578415249302
train loss:1.1520044041292181
train loss:0.9922032960074517
train loss:1.0237513171569355
train loss:0.8529673405444579
train loss:0.9730841255006724
train loss:0.6639623808582593
train loss:0.8021616181286904
train loss:0.6600843023683436
train loss:0.6247525118514222
train loss:0.7665621740903801
train loss:0.4949064582269804
train loss:0.6242407698503913
train loss:0.49830810936065156
train loss:0.5229569110564131
train loss:0.5791054054725078
train loss:0.46922702911403585
train loss:0.42852399813685893
train loss:0.6446735245788626
train loss:0.5703158994201106
train loss:0.6595882060541696
train loss:0.4358446785034126
train loss:0.561120505561482
train loss:0.7692922613678854
train loss:0.4550538698384174
train loss:0.44976007305502463
train loss:0.41405555096053503
train loss:0.504489285363871
train loss:0.42274515822952957
train loss:0.47779356807878437
train loss:0.4752809528201666
train loss:0.45331419004713713
train loss:0.4203434081258399
=== epoch:2, train acc:0.836, test acc:0.812 ===
train loss:0.48287478656060157
train loss:0.39664770268557153
train loss:0.31456944934203707
train loss:0.5127149056948094
train loss:0.3593224532519468
train loss:0.36755391375337176
train loss:0.3495835986603479
train loss:0.4158473105160699
train loss:0.32152638782854254
train loss:0.3351935316310425
train loss:0.3386612951325979
train loss:0.18844282702712958
train loss:0.26912271377640357
train loss:0.3121777776667325
train loss:0.20029675231592506
train loss:0.49685431006929187
train loss:0.35712573506052137
train loss:0.29303954388827247
train loss:0.28268623504814755
train loss:0.43256264064371464
train loss:0.3532789047860303
train loss:0.21909573044062217
train loss:0.2987549804577581
train loss:0.3410657858441422
train loss:0.20199413035215133
train loss:0.2821395624715639
train loss:0.5090209063010435
train loss:0.3952273210933893
train loss:0.3167399422840474
train loss:0.4400894246092143
train loss:0.480518877747534
train loss:0.261729055522316
train loss:0.24563443288093978
train loss:0.24588134257680302
train loss:0.3673054235311165
train loss:0.23480324881192793
train loss:0.3079535703514809
train loss:0.4086777089890201
train loss:0.2689476769178987
train loss:0.3597453652378042
train loss:0.24789994142983843
train loss:0.4943301934869385
train loss:0.2421699104974082
train loss:0.18983168547296891
train loss:0.21661684349064333
train loss:0.37133725145715885
train loss:0.2406967247806861
train loss:0.324918830455651
train loss:0.3952273759144299
train loss:0.21899109941422995
=== epoch:3, train acc:0.9, test acc:0.878 ===
train loss:0.2750013989805629
train loss:0.24291276241555315
train loss:0.3350853128435793
train loss:0.29907725898111137
train loss:0.25918216890478457
train loss:0.3574599361062101
train loss:0.5136820178214928
train loss:0.3083360869831462
train loss:0.3778759413399652
train loss:0.2558559432648089
train loss:0.34440379342648586
train loss:0.14426695877988857
train loss:0.19971915235402327
train loss:0.32518134483788863
train loss:0.23570357931035546
train loss:0.2235755391059305
train loss:0.14430484798936344
train loss:0.24909496915958637
train loss:0.26715307800452925
train loss:0.26275512187590555
train loss:0.34696169719930076
train loss:0.23039420792342058
train loss:0.2369885026392811
train loss:0.25255821778887294
train loss:0.2145247014439474
train loss:0.22293786143100808
train loss:0.21154320043925628
train loss:0.3551378221720762
train loss:0.2862347756442027
train loss:0.18399816189892518
train loss:0.22313438154914864
train loss:0.20178108744918874
train loss:0.23824391855829044
train loss:0.1364925076874601
train loss:0.24139820617345736
train loss:0.16137199956054513
train loss:0.1916070695401724
train loss:0.25605850285614673
train loss:0.18004184146592134
train loss:0.2069808692277815
train loss:0.25279228295525474
train loss:0.24571581261173805
train loss:0.19137271077104034
train loss:0.18850961536852293
train loss:0.09537895840680026
train loss:0.21420854389981617
train loss:0.35243048008730155
train loss:0.20304597229454696
train loss:0.14320999174759363
train loss:0.19578997047641714
=== epoch:4, train acc:0.914, test acc:0.891 ===
train loss:0.22523647395747026
train loss:0.16075152090059552
train loss:0.2160189685500233
train loss:0.2960884850760806
train loss:0.1710423058728277
train loss:0.13971100326641672
train loss:0.19276312929871822
train loss:0.15643147203364594
train loss:0.25905019879424895
train loss:0.09740233256554957
train loss:0.18566468669926692
train loss:0.23934105967814362
train loss:0.25352643307879186
train loss:0.1656600678637354
train loss:0.16446031891634422
train loss:0.17595973043266294
train loss:0.1711391393858455
train loss:0.18185711440780009
train loss:0.16178604735854793
train loss:0.3861038493559738
train loss:0.21356894394103812
train loss:0.10125251140610594
train loss:0.0884653685875568
train loss:0.21474737554448467
train loss:0.21718501575539265
train loss:0.23605964813303204
train loss:0.11183338516996898
train loss:0.10844558563736512
train loss:0.28016172725037125
train loss:0.17621893514253043
train loss:0.23373102648595107
train loss:0.18579159327300443
train loss:0.1879352378446844
train loss:0.10543137961225306
train loss:0.11810437165766471
train loss:0.08780036167031426
train loss:0.27520132081715976
train loss:0.09568714304506458
train loss:0.11385472947933495
train loss:0.26024531183026783
train loss:0.14701639050657492
train loss:0.06308029729343931
train loss:0.09249292526957482
train loss:0.16727598837211463
train loss:0.27901064516710533
train loss:0.21527460257396572
train loss:0.08133103141457879
train loss:0.17190928656470308
train loss:0.19573541657507104
train loss:0.13833996892606854
=== epoch:5, train acc:0.947, test acc:0.915 ===
train loss:0.1767331562639304
train loss:0.07546694445357238
train loss:0.12791332850155457
train loss:0.22018597193663947
train loss:0.08422592773025013
train loss:0.16820917844169148
train loss:0.14763439948818338
train loss:0.1299441820449363
train loss:0.19206656543800052
train loss:0.27655635834997455
train loss:0.11862964263850519
train loss:0.1754077232390669
train loss:0.14980299266693162
train loss:0.13942259978914093
train loss:0.11667477180592659
train loss:0.10708807108715565
train loss:0.13833932136128688
train loss:0.18386764716500878
train loss:0.1286296325743739
train loss:0.10941434605023966
train loss:0.1858986998348518
train loss:0.18738144595001344
train loss:0.1482712696109215
train loss:0.18871603117456068
train loss:0.1078288624988147
train loss:0.1514518610533237
train loss:0.15929581870950688
train loss:0.1394987808310998
train loss:0.16899933427659103
train loss:0.18583223369279944
train loss:0.09625284887878438
train loss:0.0982323519848766
train loss:0.06795126421951297
train loss:0.14041522576682736
train loss:0.1339865043064452
train loss:0.12558617108339334
train loss:0.07266824199304439
train loss:0.18281903706555422
train loss:0.09387994261768824
train loss:0.1229250026717219
train loss:0.2812471072120683
train loss:0.24620247290411282
train loss:0.10380931258114577
train loss:0.1489843640456824
train loss:0.1813310995045713
train loss:0.1611967234454589
train loss:0.03550139236674415
train loss:0.10677129758318628
train loss:0.15192212876577474
train loss:0.07318091379025704
=== epoch:6, train acc:0.951, test acc:0.916 ===
train loss:0.1583381575188071
train loss:0.1006959622951142
train loss:0.12677632400577754
train loss:0.05829521331180015
train loss:0.27816947839267664
train loss:0.17014754131621904
train loss:0.0571295397895939
train loss:0.21455288662970254
train loss:0.22709031697614296
train loss:0.14049220261288722
train loss:0.06933893038712542
train loss:0.1378826659077521
train loss:0.06395167209898817
train loss:0.22189942342508012
train loss:0.08684499188382883
train loss:0.09929236570994843
train loss:0.1578137004328837
train loss:0.1682167687460379
train loss:0.1467348617281436
train loss:0.11181311596893817
train loss:0.11625836628340412
train loss:0.10346686999495933
train loss:0.09414665362350566
train loss:0.16828568705633618
train loss:0.10553451348816133
train loss:0.07591124855682643
train loss:0.06779125380579222
train loss:0.22314786073383236
train loss:0.0928796249919706
train loss:0.2009862775848919
train loss:0.09735053392193364
train loss:0.0772039944029596
train loss:0.1347401543981549
train loss:0.12676667239171036
train loss:0.10765398539723972
train loss:0.3028025293998835
train loss:0.14494417881130395
train loss:0.15195225018334504
train loss:0.10991440910611674
train loss:0.15668658018257195
train loss:0.21204952278019604
train loss:0.10895972748094261
train loss:0.15100215419828716
train loss:0.11922449888265935
train loss:0.11775386591906971
train loss:0.1365561076193355
train loss:0.07008037108195422
train loss:0.10843651061876061
train loss:0.06439665333532595
train loss:0.11537344525829331
=== epoch:7, train acc:0.959, test acc:0.937 ===
train loss:0.14415072101294246
train loss:0.12345904607845509
train loss:0.11439496595348853
train loss:0.12310366752875605
train loss:0.07982358746682024
train loss:0.09143892556940375
train loss:0.16860334512106132
train loss:0.0897591908251134
train loss:0.07100324493848266
train loss:0.1552716909090135
train loss:0.11217802345574318
train loss:0.09721993510226459
train loss:0.12426054548629702
train loss:0.1700808078313596
train loss:0.14562913420703436
train loss:0.07097808257950483
train loss:0.07736955291911332
train loss:0.1096150783824645
train loss:0.09196705309225253
train loss:0.11678712741220174
train loss:0.09964264652794531
train loss:0.13089923755313063
train loss:0.11864469620288828
train loss:0.07299544603793157
train loss:0.09061800429739626
train loss:0.14023209381205684
train loss:0.0543137357561973
train loss:0.11591373484715145
train loss:0.10262345857745321
train loss:0.12241426978613636
train loss:0.1132751344687272
train loss:0.055343207158085855
train loss:0.04638886460007529
train loss:0.03960578536349254
train loss:0.05605015389919306
train loss:0.04022652922825427
train loss:0.08560170441574451
train loss:0.06005124616610811
train loss:0.06636488174587701
train loss:0.07277720823186094
train loss:0.1141302148470003
train loss:0.05656720527633294
train loss:0.15949573170294062
train loss:0.07326187480826951
train loss:0.05169389172548916
train loss:0.0905509248783933
train loss:0.10557005285138972
train loss:0.07869680941368577
train loss:0.1206496803860759
train loss:0.09724866259425959
=== epoch:8, train acc:0.961, test acc:0.936 ===
train loss:0.06016180464060048
train loss:0.17003595279678194
train loss:0.06901460915684528
train loss:0.09932419700184267
train loss:0.060096688044248614
train loss:0.0666533442282605
train loss:0.036687749140768194
train loss:0.10183442259366203
train loss:0.09936337626715432
train loss:0.055315162410899496
train loss:0.09639349336916415
train loss:0.1706838975480286
train loss:0.07392134559028461
train loss:0.07515087319160571
train loss:0.06763322391757348
train loss:0.11203413730395213
train loss:0.051437394479895024
train loss:0.07745128957024996
train loss:0.040042275857666086
train loss:0.08698308709985814
train loss:0.05637826919582512
train loss:0.13252789021913836
train loss:0.10285513010516296
train loss:0.09628296469182353
train loss:0.0809639098663507
train loss:0.06329983762345363
train loss:0.1766232967734827
train loss:0.043236620016788414
train loss:0.11264458325026014
train loss:0.06044428968285257
train loss:0.08758964932130135
train loss:0.05646798631994245
train loss:0.05028611559269132
train loss:0.18296620399387745
train loss:0.02821557718021236
train loss:0.06301994397091627
train loss:0.09790226277026871
train loss:0.038863757198043226
train loss:0.08767650607275301
train loss:0.12551007554869606
train loss:0.02521292929027244
train loss:0.04288254311484805
train loss:0.0596083790834597
train loss:0.07939833281508865
train loss:0.08171487830871445
train loss:0.11301824214756406
train loss:0.040330946150086616
train loss:0.09222910533637885
train loss:0.04466484995307689
train loss:0.06187071749593391
=== epoch:9, train acc:0.97, test acc:0.941 ===
train loss:0.11444160882084149
train loss:0.0921758245621827
train loss:0.12892593573062142
train loss:0.05687231687803718
train loss:0.032989219275164634
train loss:0.0761704671691159
train loss:0.031481305884941774
train loss:0.07356544692168358
train loss:0.06060281495664725
train loss:0.029530735195270042
train loss:0.07257660515206817
train loss:0.04247180421848474
train loss:0.043584198093060314
train loss:0.026957890954644022
train loss:0.04361309685342429
train loss:0.06549221396574201
train loss:0.06061659012330833
train loss:0.07763402557341516
train loss:0.05012705188521575
train loss:0.08750542150572489
train loss:0.09492107168582636
train loss:0.05251534682657375
train loss:0.03960946107639741
train loss:0.051073187760018825
train loss:0.06440031345152206
train loss:0.05516000596163979
train loss:0.05281076711679615
train loss:0.1406948525757371
train loss:0.08102054754655069
train loss:0.10270438711238683
train loss:0.07094217346080367
train loss:0.026450642452721176
train loss:0.08569216380814938
train loss:0.04549302470778986
train loss:0.09007611451680189
train loss:0.02751737285831809
train loss:0.08242415593394224
train loss:0.07648078071660772
train loss:0.028295123621874193
train loss:0.03593663037468971
train loss:0.016341092504205578
train loss:0.11048537766181717
train loss:0.01979354954599892
train loss:0.0544014697137024
train loss:0.038902228934781194
train loss:0.03064489499623011
train loss:0.06624115705204836
train loss:0.05946588268334266
train loss:0.09469434813328861
train loss:0.047406523550006775
=== epoch:10, train acc:0.977, test acc:0.944 ===
train loss:0.03774895683865876
train loss:0.04645038715697364
train loss:0.06595226459786313
train loss:0.02936477249467078
train loss:0.05083235895609916
train loss:0.04724479256228789
train loss:0.08251075215287226
train loss:0.09924525172144322
train loss:0.044818970172604965
train loss:0.05266715140266959
train loss:0.03789879233122178
train loss:0.02742937650275703
train loss:0.08052287404041994
train loss:0.015509515549972376
train loss:0.037334544083008236
train loss:0.058270849793768474
train loss:0.06129402301594206
train loss:0.0659225821808316
train loss:0.02124681079596732
train loss:0.0756674898893655
train loss:0.07701388302034136
train loss:0.07121900207830012
train loss:0.09231483788791875
train loss:0.043137631825267454
train loss:0.048591658996335454
train loss:0.07193170026653174
train loss:0.12465596848538534
train loss:0.060745279752068754
train loss:0.05960883830794013
train loss:0.02567345122342206
train loss:0.04013554935121921
train loss:0.029322911887716047
train loss:0.03310629390086694
train loss:0.07386397464371719
train loss:0.11703861963050106
train loss:0.026839030567732923
train loss:0.07298651655350309
train loss:0.07576892854344855
train loss:0.04625989297639279
train loss:0.12652881284123993
train loss:0.02876293618943827
train loss:0.021789385743584546
train loss:0.08205370665418546
train loss:0.06602137827566429
train loss:0.028707283694250577
train loss:0.07654380359350295
train loss:0.021763993627747644
train loss:0.06257846008049212
train loss:0.060387593262879624
train loss:0.015315833666430943
=== epoch:11, train acc:0.986, test acc:0.956 ===
train loss:0.05118763173705337
train loss:0.02022100952138115
train loss:0.06524617210468735
train loss:0.029265525030701536
train loss:0.07155097750643416
train loss:0.02316995896172591
train loss:0.04865767833668083
train loss:0.0596493139878537
train loss:0.0541177805231111
train loss:0.034956767332247354
train loss:0.04775703064998674
train loss:0.02019487601662113
train loss:0.022110516793363625
train loss:0.03692257497869942
train loss:0.024814013096542326
train loss:0.12160497538144847
train loss:0.01733052447220757
train loss:0.03913949231790918
train loss:0.019401039062515692
train loss:0.03459462837476637
train loss:0.018355665825376927
train loss:0.02481204861303526
train loss:0.04310483459777173
train loss:0.0628470201563906
train loss:0.06492757148406261
train loss:0.02613561000516099
train loss:0.027000829570625863
train loss:0.07977697606753767
train loss:0.0234846616331059
train loss:0.031281179213225936
train loss:0.026882283401687305
train loss:0.014498329476595595
train loss:0.022774673004388825
train loss:0.024647130352799407
train loss:0.05159095261071845
train loss:0.04869492932910514
train loss:0.020420718836537396
train loss:0.015424034682818664
train loss:0.06327281339273089
train loss:0.013204372641686217
train loss:0.02033278100193879
train loss:0.03341018829956432
train loss:0.008517927221416506
train loss:0.04011110704223927
train loss:0.018167341642666084
train loss:0.016609027031104135
train loss:0.019622617979036923
train loss:0.022343181547569126
train loss:0.05226038460714267
train loss:0.024797947349125077
=== epoch:12, train acc:0.983, test acc:0.96 ===
train loss:0.03916122589522149
train loss:0.042112551806090234
train loss:0.0777740554160325
train loss:0.0635449526941395
train loss:0.024290114563439217
train loss:0.04093903579884853
train loss:0.04559365616931192
train loss:0.01735923855046565
train loss:0.013315842487331496
train loss:0.055124585661548584
train loss:0.025035073943343276
train loss:0.04038825551286112
train loss:0.016562939767218666
train loss:0.02989034646980253
train loss:0.04649504836311917
train loss:0.05250833841827942
train loss:0.05275244246321487
train loss:0.03468740125113473
train loss:0.01763195935518239
train loss:0.013909067095774769
train loss:0.02447007012462556
train loss:0.018529494952788553
train loss:0.02173823449647034
train loss:0.07898427426338342
train loss:0.009469323599975365
train loss:0.045933321479116336
train loss:0.01391124249897898
train loss:0.02940989049767459
train loss:0.07597925526878456
train loss:0.03889702039082736
train loss:0.01911660174479075
train loss:0.06124798100281044
train loss:0.03656731986370569
train loss:0.06282552490513744
train loss:0.0357510163306923
train loss:0.036223296976935784
train loss:0.047909328910902514
train loss:0.00943370067649841
train loss:0.019758218934347614
train loss:0.017724149853061033
train loss:0.057152868609558205
train loss:0.028277627635277244
train loss:0.028758225237129228
train loss:0.0471471682119804
train loss:0.0326579057293643
train loss:0.027766612611566988
train loss:0.03014548188192835
train loss:0.06023158901271109
train loss:0.020508962805168864
train loss:0.08163685637438305
=== epoch:13, train acc:0.989, test acc:0.956 ===
train loss:0.019655416589027017
train loss:0.0583567009366889
train loss:0.01870912292428663
train loss:0.014661606822673005
train loss:0.022071354476898696
train loss:0.014774943026958864
train loss:0.014963253198612565
train loss:0.02421558881671392
train loss:0.017012013639041482
train loss:0.019258841020374687
train loss:0.026871189154931172
train loss:0.025831802476142945
train loss:0.022820395635617947
train loss:0.022146265646684267
train loss:0.023294383064996392
train loss:0.017774838137654164
train loss:0.053093952413006004
train loss:0.009930270031006305
train loss:0.027076373363904827
train loss:0.014314342956027216
train loss:0.04983050594180742
train loss:0.0349784729258482
train loss:0.028949639459386757
train loss:0.009154081607647415
train loss:0.04000202359612355
train loss:0.04535813955468118
train loss:0.039719749861448446
train loss:0.0146531598147277
train loss:0.027079754006035746
train loss:0.017468247594383368
train loss:0.021583911367508878
train loss:0.00732085888658847
train loss:0.02761736892823013
train loss:0.023030438249534255
train loss:0.02261318669553839
train loss:0.013251376135612494
train loss:0.030983322049749962
train loss:0.01203194187685796
train loss:0.02183029995978277
train loss:0.01801939789248755
train loss:0.037210728237642196
train loss:0.016695975487375343
train loss:0.01548912577937866
train loss:0.009930522490837002
train loss:0.013105955683149241
train loss:0.014696632073984372
train loss:0.01073841012244509
train loss:0.019303451058528254
train loss:0.010337569484810983
train loss:0.011834700550931197
=== epoch:14, train acc:0.993, test acc:0.963 ===
train loss:0.012706433883810951
train loss:0.008195234404199423
train loss:0.07376081946651818
train loss:0.008318503820559126
train loss:0.011234342756964081
train loss:0.007261945401217772
train loss:0.04761767551892596
train loss:0.019611070278547117
train loss:0.007513151735086706
train loss:0.010908708883795613
train loss:0.023603225976154024
train loss:0.013005706864442293
train loss:0.06640254028029968
train loss:0.018843618575687747
train loss:0.01598797520076916
train loss:0.04046898911390117
train loss:0.009897295487244098
train loss:0.018148662367769103
train loss:0.016204961987245258
train loss:0.021923775049801496
train loss:0.012186267382937347
train loss:0.025317397597361478
train loss:0.017915216084462726
train loss:0.04112017216818607
train loss:0.00960820266743732
train loss:0.014188002517323354
train loss:0.009930873516467115
train loss:0.01524814565480661
train loss:0.005449533808203894
train loss:0.01200196926752199
train loss:0.010580443093539187
train loss:0.008161989834547422
train loss:0.02221011014731475
train loss:0.022918057529847356
train loss:0.03830891338995068
train loss:0.03943971673981061
train loss:0.009787609258596746
train loss:0.026119299260105196
train loss:0.019601380156289802
train loss:0.01951480302774732
train loss:0.011069097527643616
train loss:0.011919765537808779
train loss:0.01601289552752917
train loss:0.010895976833585681
train loss:0.014249572151909758
train loss:0.04616193429116965
train loss:0.010272171572045291
train loss:0.004445386470127315
train loss:0.011306921103233851
train loss:0.012365979968096949
=== epoch:15, train acc:0.994, test acc:0.959 ===
train loss:0.04527368661729919
train loss:0.026945988704939958
train loss:0.009620412836276463
train loss:0.0067830789387076755
train loss:0.03407455770664322
train loss:0.02385412046769304
train loss:0.02116420538365098
train loss:0.007639734488561193
train loss:0.007343918416560155
train loss:0.010455607911686095
train loss:0.010776657661115779
train loss:0.007076118700297338
train loss:0.011067739451059854
train loss:0.01413692955903456
train loss:0.008195133259146396
train loss:0.05993990849288216
train loss:0.009190149284195849
train loss:0.004043388262632377
train loss:0.007741099846639511
train loss:0.02660351571530523
train loss:0.019005817491689326
train loss:0.005701655001707397
train loss:0.013290648007988713
train loss:0.00928624940334675
train loss:0.009525217567016268
train loss:0.016706424151265206
train loss:0.022816957284876035
train loss:0.016689585316411692
train loss:0.012455672560911455
train loss:0.008581528358624824
train loss:0.0426029495395151
train loss:0.02126584781633759
train loss:0.014646325546407424
train loss:0.01887033473844019
train loss:0.00820722452406045
train loss:0.013029602269811456
train loss:0.020009800070954695
train loss:0.015600348682223566
train loss:0.010192092464960906
train loss:0.017791307039855774
train loss:0.023715475484235134
train loss:0.01279284435373007
train loss:0.013186394239526883
train loss:0.012677657498359593
train loss:0.019814956793187736
train loss:0.035289548095552445
train loss:0.020524006270723944
train loss:0.011868959893881356
train loss:0.025054044912782153
train loss:0.006121930923416148
=== epoch:16, train acc:0.993, test acc:0.967 ===
train loss:0.033302883990778805
train loss:0.012865272153088424
train loss:0.02563962767773337
train loss:0.015727845423255612
train loss:0.00750688761248828
train loss:0.020820116564350746
train loss:0.010557082388006993
train loss:0.009699752436190178
train loss:0.010782491410922333
train loss:0.005457401796578886
train loss:0.015904105535258145
train loss:0.008662864466913962
train loss:0.014155918629259006
train loss:0.022481508791640084
train loss:0.02173023759575264
train loss:0.01751088766526991
train loss:0.005819758155008057
train loss:0.02129823200912289
train loss:0.029267847233649884
train loss:0.014350094691432266
train loss:0.006857268251965607
train loss:0.018391099091639745
train loss:0.02969964076171729
train loss:0.01205726822608632
train loss:0.013147687027517299
train loss:0.007850722888244987
train loss:0.008990408030002941
train loss:0.014277842106718452
train loss:0.009659086203128059
train loss:0.04405757658705242
train loss:0.0071812182524052925
train loss:0.012788161380890563
train loss:0.003330742409727396
train loss:0.013527119805498127
train loss:0.014362698710184207
train loss:0.013536987980197599
train loss:0.022106692824573174
train loss:0.011173518521913027
train loss:0.017540447155767514
train loss:0.006150276382904599
train loss:0.006882445634457177
train loss:0.007244943546324845
train loss:0.009678235930034423
train loss:0.00614252912684993
train loss:0.009977692377614535
train loss:0.014542227099100115
train loss:0.031002236607655866
train loss:0.03109991646871924
train loss:0.008815011062804724
train loss:0.004903814185130312
=== epoch:17, train acc:0.996, test acc:0.963 ===
train loss:0.003731682390814028
train loss:0.013653523374898214
train loss:0.03733293165725232
train loss:0.007394580335399023
train loss:0.01598498629915459
train loss:0.014306869095921016
train loss:0.013895986580440023
train loss:0.006014691338202585
train loss:0.022803319796907764
train loss:0.014200142991650537
train loss:0.015305542831755841
train loss:0.01656505309918506
train loss:0.010474822981518616
train loss:0.007392282897609531
train loss:0.007733194707733657
train loss:0.009155032331338919
train loss:0.008965184419791048
train loss:0.0023046349943642956
train loss:0.00991003723874249
train loss:0.011612484246103444
train loss:0.008574192931195908
train loss:0.02347557430178743
train loss:0.01732372002665184
train loss:0.020793262946044683
train loss:0.02681541901857447
train loss:0.007769421489603011
train loss:0.005988861021130396
train loss:0.012742211913398787
train loss:0.01013776777249648
train loss:0.006048596587220693
train loss:0.005733079559706556
train loss:0.011406859980527189
train loss:0.004277331538442165
train loss:0.007851313177422563
train loss:0.025554815206568052
train loss:0.04308531680435618
train loss:0.00802731067393725
train loss:0.004772185053837823
train loss:0.005210869851972447
train loss:0.010173984477120798
train loss:0.00637029362915087
train loss:0.007923884325550534
train loss:0.008591989121082609
train loss:0.0055583978467098425
train loss:0.02328140363226697
train loss:0.03556854924088624
train loss:0.019988743975519134
train loss:0.008226457791805185
train loss:0.008763340547042529
train loss:0.010026090092395029
=== epoch:18, train acc:0.998, test acc:0.964 ===
train loss:0.008852001789847139
train loss:0.013211893718210754
train loss:0.014328912548474626
train loss:0.00524686791840034
train loss:0.014910883831980288
train loss:0.006343200067203364
train loss:0.018889826602591957
train loss:0.006467565444997772
train loss:0.0066100056908839026
train loss:0.012312496096138482
train loss:0.005651906919153357
train loss:0.004151681212938266
train loss:0.005314303213304307
train loss:0.007481377058066713
train loss:0.012271445943166726
train loss:0.012611243432924933
train loss:0.013645327341419038
train loss:0.00839379917030692
train loss:0.019004771854618206
train loss:0.00758670730253598
train loss:0.005851591314534118
train loss:0.01365865423010738
train loss:0.009217247271528433
train loss:0.0065934099334440995
train loss:0.005222186332696855
train loss:0.006362968965659736
train loss:0.009237644996915203
train loss:0.009275188308423103
train loss:0.03698956051878061
train loss:0.006376460403810434
train loss:0.010409302081646152
train loss:0.006495355359192375
train loss:0.005013033680282363
train loss:0.003203965305059122
train loss:0.0036331679081871315
train loss:0.0034638408510755396
train loss:0.011278559501450326
train loss:0.0046910467715666785
train loss:0.0036397605739883166
train loss:0.0078001822687587055
train loss:0.004326861750540386
train loss:0.010144356583964962
train loss:0.0036925256335268914
train loss:0.005901932187892204
train loss:0.006723056769269201
train loss:0.004476582150283273
train loss:0.003561426885563302
train loss:0.017212444019008323
train loss:0.006040604117551829
train loss:0.003126586985811897
=== epoch:19, train acc:0.999, test acc:0.961 ===
train loss:0.010048316327170374
train loss:0.002323331301830863
train loss:0.003269397715926978
train loss:0.006050755248444847
train loss:0.00890315629499221
train loss:0.008556443081631044
train loss:0.003907009654558611
train loss:0.003774805396740983
train loss:0.0046792527640713046
train loss:0.004461451335876496
train loss:0.00879017034471494
train loss:0.0030130311572697287
train loss:0.009555318862460182
train loss:0.0033965228340498517
train loss:0.011076967462993179
train loss:0.00556503864247078
train loss:0.004355977716067771
train loss:0.013372191364719779
train loss:0.004330293783030104
train loss:0.003289964999738831
train loss:0.00941313248534362
train loss:0.00511893250695095
train loss:0.004322942199477358
train loss:0.003943446364980666
train loss:0.003783056515956066
train loss:0.011350709747500898
train loss:0.0051304792791184006
train loss:0.01180651089738642
train loss:0.011598820483097915
train loss:0.022584976345120446
train loss:0.004654361763089469
train loss:0.0025788264007069643
train loss:0.003807560833484285
train loss:0.007343250999354329
train loss:0.0036456711109706334
train loss:0.0019896734643619664
train loss:0.003958459862041275
train loss:0.0063303013108067215
train loss:0.00463288338277793
train loss:0.013248932802438607
train loss:0.0024479057955587246
train loss:0.005444470797026964
train loss:0.004100737032649946
train loss:0.008612733000542088
train loss:0.008807699724185082
train loss:0.00536372932921479
train loss:0.00547649851762111
train loss:0.006418423376667743
train loss:0.005606748665635426
train loss:0.001335167089484916
=== epoch:20, train acc:0.999, test acc:0.964 ===
train loss:0.0017870707206491926
train loss:0.0029161585842194847
train loss:0.013437181553056107
train loss:0.0047801995248617
train loss:0.0014121230815006406
train loss:0.002728966698378382
train loss:0.00508392081145934
train loss:0.0021256489850431676
train loss:0.0027785160704158905
train loss:0.016212332837075828
train loss:0.004175903654153577
train loss:0.011430416933773226
train loss:0.0034282206383511866
train loss:0.003698167037393495
train loss:0.005042861504825119
train loss:0.0018707728527493112
train loss:0.0025694331433879806
train loss:0.0032229255770904346
train loss:0.0052899624889588374
train loss:0.005810554665407193
train loss:0.004565176172243562
train loss:0.009869831689145687
train loss:0.0038323504492333805
train loss:0.006326648576506523
train loss:0.002582897716138186
train loss:0.006512848848851544
train loss:0.007099529068860667
train loss:0.015237428217474704
train loss:0.0019031221661252994
train loss:0.004530653448249284
train loss:0.00315924415631518
train loss:0.00305274278256817
train loss:0.01081103066125715
train loss:0.0042716993348632945
train loss:0.007749834207104994
train loss:0.004574931775760223
train loss:0.004336685551180274
train loss:0.004872531472464039
train loss:0.005399553687031059
train loss:0.003485320022192603
train loss:0.005128190734278354
train loss:0.004143203389479184
train loss:0.0011304606752731302
train loss:0.0038273436855024946
train loss:0.002559888596623478
train loss:0.010037381343690626
train loss:0.002772364988551278
train loss:0.001259999618648218
train loss:0.0024857710752820973
=============== Final Test Accuracy ===============
test acc:0.966